---
title: AI Pet Species Classifier
emoji: ğŸ¾
colorFrom: gray
colorTo: blue
sdk: gradio
python_version: 3.12
app_file: app.py
pinned: false
license: mit
---

<div align="center">

# ğŸ¾ AI Pet Species Classifier
### *Deep Learning-Powered Multi-Class Image Classification System*

[![Python 3.12](https://img.shields.io/badge/Python-3.12-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![fastai](https://img.shields.io/badge/fastai-00A98F?style=for-the-badge&logo=fastai&logoColor=white)](https://www.fast.ai/)
[![Gradio](https://img.shields.io/badge/Gradio-FF6F00?style=for-the-badge&logo=gradio&logoColor=white)](https://gradio.app/)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Spaces-FFD21E?style=for-the-badge)](https://huggingface.co/spaces)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)

**[ğŸš€ Live Demo](https://huggingface.co/spaces/breznev/pet-classifier)** â€¢ **[ğŸ““ Training Notebook](pet-identifier.ipynb)** â€¢ **[ğŸ“Š Model Metrics](#-model-performance)**

*A production-ready deep learning application achieving 98% validation accuracy through transfer learning and data augmentation*

---

### ğŸ‘¨â€ğŸ’» Developer

**é¦¬ç››ä¸­ (Ma Sheng-Zhong)** â€¢ `4B1YZ001`  
*Computer Science & Information Engineering*  
Southern Taiwan University of Science and Technology (STUST)

</div>

---

## ğŸ“‹ Table of Contents

- [ğŸ¯ Overview](#-overview)
- [âœ¨ Key Features](#-key-features)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“Š Model Performance](#-model-performance)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ’» Development](#-development)
- [ğŸ”¬ Technical Deep Dive](#-technical-deep-dive)
- [ğŸ“ Learning Outcomes](#-learning-outcomes)
- [ğŸ›£ï¸ Future Enhancements](#ï¸-future-enhancements)
- [ğŸ“„ License](#-license)

---

## ğŸ¯ Overview

A **state-of-the-art computer vision system** that classifies 7 common household pets using deep convolutional neural networks. This project demonstrates end-to-end ML engineeringâ€”from data preprocessing to production deploymentâ€”leveraging modern MLOps best practices.

### Supported Species

<div align="center">

| ğŸ± Cat | ğŸ¶ Dog | ğŸ  Goldfish | ğŸ¹ Hamster | ğŸ¢ Turtle | ğŸ¦œ Parrot | ğŸ Snake |
|:------:|:------:|:-----------:|:----------:|:---------:|:---------:|:--------:|
| è²“ | ç‹— | é‡‘é­š | å€‰é¼  | çƒé¾œ | é¸šéµ¡ | è›‡ |

</div>

### ğŸ¬ Demo Interface

The application features a **bilingual (English/Traditional Chinese)** Gradio interface with:
- Real-time image upload and prediction
- Top-3 confidence scores with probability distribution
- Example gallery for quick testing
- Responsive design with premium UI/UX
- Accessibility-first design approach

---

## âœ¨ Key Features

### ğŸ“ Machine Learning Excellence
- **Transfer Learning**: Fine-tuned ResNet34 pre-trained on ImageNet
- **98% Validation Accuracy**: Optimized through data augmentation and hyperparameter tuning
- **Robust Generalization**: Trained on diverse animal image dataset (90 species subset)
- **Production-Ready**: Exported as optimized `.pkl` inference model

### ğŸ› ï¸ Technical Sophistication
- **Modern Stack**: PyTorch + fastai for rapid prototyping
- **Cloud Deployment**: Hosted on Hugging Face Spaces with auto-scaling
- **Interactive UI**: Custom-styled Gradio app with gradient headers and adaptive theming
- **Bilingual Support**: Seamless English/Traditional Chinese localization

### ğŸ” Engineering Best Practices
- Clean, documented codebase with separation of concerns
- Jupyter notebook for reproducible training pipeline
- Version control with Git and `.gitignore` for ML artifacts
- MIT License for open-source contribution

---

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A[Input Image] --> B[Preprocessing]
    B --> C[ResNet34 CNN]
    C --> D[Feature Extraction]
    D --> E[Custom Classifier Head]
    E --> F[Softmax Layer]
    F --> G[7-Class Probabilities]
    
    style C fill:#3b82f6,stroke:#1e40af,color:#fff
    style E fill:#2dd4bf,stroke:#0d9488,color:#fff
```

### Model Pipeline

1. **Input Processing**: Images resized and normalized using ImageNet statistics
2. **Feature Extraction**: ResNet34 backbone extracts high-level visual features
3. **Classification Head**: Fully connected layers adapted for 7-class output
4. **Output**: Probability distribution across pet species

### Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Deep Learning** | PyTorch 2.x | Core neural network framework |
| **High-Level API** | fastai v2 | Rapid experimentation & transfer learning |
| **Web Interface** | Gradio 4.x | Interactive model deployment |
| **Hosting** | Hugging Face Spaces | Serverless cloud inference |
| **Notebook** | Jupyter | Exploratory data analysis & training |

---

## ï¿½ Model Performance

### Training Progression

| Metric | Baseline (Pre-training) | After Data Augmentation | Final Model |
|--------|------------------------|------------------------|-------------|
| **Validation Accuracy** | 76% | 94% | **98%** |
| **Training Time** | â€” | ~15 min | ~25 min |
| **Data Augmentation** | âŒ | âœ… Random flips, rotation | âœ… + color jitter |

### Key Results
- **Achieved 98% accuracy** on held-out validation set
- **22% improvement** over baseline through transfer learning
- **Low overfitting**: Training and validation loss converged smoothly
- **Confusion Matrix Analysis**: Minimal misclassification between visually similar species

> *Training performed on Google Colab with T4 GPU acceleration. Full metrics available in [pet-identifier.ipynb](pet-identifier.ipynb)*

---

## ğŸš€ Quick Start

### Option 1: Try Online (Recommended)

Visit the **live demo** hosted on Hugging Face Spaces:  
ğŸ‘‰ **[Launch Application](https://huggingface.co/spaces/breznev/pet-classifier)**

### Option 2: Run Locally

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/pet-classifier.git
cd pet-classifier

# Install dependencies
pip install -r requirements.txt

# Launch Gradio app
python app.py
```

Then open your browser to `http://localhost:7860`

### Requirements
- Python 3.12+
- 2GB+ RAM (for model inference)
- Modern web browser

---

## ğŸ’» Development

### Project Structure

```
pet-classifier/
â”œâ”€â”€ app.py                    # Gradio web application
â”œâ”€â”€ pet_classifier_v1.pkl     # Trained model weights (87MB)
â”œâ”€â”€ pet-identifier.ipynb      # Full training notebook
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ example_*.jpg             # Sample test images
â””â”€â”€ README.md                 # This file
```

### Reproducing the Model

1. **Open Training Notebook**  
   Launch [pet-identifier.ipynb](pet-identifier.ipynb) in Jupyter/Colab

2. **Dataset Preparation**  
   Download the "90 Different Animals" dataset and create symbolic links for 7 target species

3. **Training Pipeline**  
   ```python
   # Transfer learning with ResNet34
   learn = vision_learner(dls, resnet34, metrics=error_rate)
   learn.fine_tune(epochs=5)
   ```

4. **Export Model**  
   ```python
   learn.export('pet_classifier_v1.pkl')
   ```

### Customizing the UI

The Gradio interface uses custom CSS with adaptive theming. Key customization points in [app.py](app.py):
- **Line 26-83**: Premium CSS styling with gradient headers
- **Line 88-94**: Student name/ID branding
- **Line 137-175**: Bilingual documentation accordion

---

## ğŸ”¬ Technical Deep Dive

### Why Transfer Learning?

Instead of training a CNN from scratch (which requires massive datasets and compute), this project leverages **transfer learning**:

1. **Pre-trained Backbone**: ResNet34 trained on ImageNet (1.4M images, 1000 classes)
2. **Feature Reuse**: Lower layers detect universal patterns (edges, textures)
3. **Fine-Tuning**: Only retrain final layers for pet-specific features
4. **Result**: 98% accuracy with <30 minutes of training

### Data Augmentation Strategy

Applied transformations to prevent overfitting:
- Random horizontal flips
- Small rotation (Â±10 degrees)
- Color jittering (brightness, contrast)
- Cutout regularization

### Deployment Architecture

```mermaid
graph TD
    A[User Browser] -->|HTTPS| B[Hugging Face Spaces]
    B -->|Load Model| C[pet_classifier_v1.pkl]
    C -->|Inference| D[ResNet34 + Custom Head]
    D -->|Predictions| E[Gradio Frontend]
    E -->|Response| A
    
    style B fill:#FFD21E,stroke:#F59E0B,color:#000
    style D fill:#3b82f6,stroke:#1e40af,color:#fff
```

---

## ğŸ“ Learning Outcomes

This project demonstrates proficiency in:

### Machine Learning
- âœ… Convolutional Neural Networks (CNNs) architecture
- âœ… Transfer learning and fine-tuning strategies
- âœ… Data augmentation and regularization techniques
- âœ… Model evaluation using confusion matrices

### Software Engineering
- âœ… Clean, production-ready Python code
- âœ… Git version control and dependency management
- âœ… Full-stack ML deployment (training â†’ inference â†’ web UI)
- âœ… Bilingual internationalization (i18n)

### MLOps & Deployment
- âœ… Model serialization and optimization
- âœ… Cloud hosting on Hugging Face Spaces
- âœ… Interactive UI development with Gradio
- âœ… Documentation and reproducibility

---

## ğŸ›£ï¸ Future Enhancements

### Technical Improvements
- [ ] **Expand Dataset**: Add more species and increase training samples
- [ ] **Model Optimization**: Quantization for faster mobile inference
- [ ] **Explainability**: Integrate Grad-CAM for prediction visualization
- [ ] **API Development**: RESTful API for programmatic access

### Features
- [ ] **Batch Prediction**: Upload multiple images simultaneously
- [ ] **Confidence Thresholding**: Alert users on low-confidence predictions
- [ ] **User Feedback Loop**: Collect misclassifications for continuous improvement
- [ ] **Mobile App**: Deploy as native iOS/Android application

### Research Directions
- [ ] Compare performance with Vision Transformers (ViT)
- [ ] Multi-label classification (e.g., breed + species)
- [ ] Few-shot learning for rare species

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

### ğŸŒŸ Acknowledgments

Built with [fastai](https://www.fast.ai/) â€¢ Deployed on [Hugging Face Spaces](https://huggingface.co/spaces) â€¢ Styled with [Gradio](https://gradio.app/)

**Developed as part of Deep Learning coursework at STUST CSIE**

---

*If you found this project useful, please consider starring â­ the repository!*

</div>
